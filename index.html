<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Conversational Voice AI</title>
  <style>
    body {
      font-family: sans-serif;
      display: flex;
      align-items: center;
      justify-content: center;
      height: 100vh;
      margin: 0;
      background: linear-gradient(135deg, #1f1d36 0%, #2a284a 100%);
      color: #e2e8f0;
    }
    .container {
      background: #363456;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 8px 16px rgba(0,0,0,0.3);
      text-align: center;
      width: 90%;
      max-width: 400px;
    }
    h2 {
      color: #cbd5e1;
    }
    textarea {
      width: 100%;
      height: 200px;
      margin-top: 1rem;
      padding: 0.5rem;
      border-radius: 6px;
      border: 1px solid #4a486b;
      font-size: 1rem;
      background-color: #363456;
      color: #e2e8f0;
    }
  </style>
</head>
<body>
  <div class="container">
    <h2>ðŸŽ¤ Talking AI (ASR + TTS)</h2>
    <textarea id="transcript" readonly placeholder="Start speakingâ€¦ AI will respond."></textarea><br>
  </div>

  <script>
    const WEBHOOK_URL = "https://auto.mithil.hackclub.app/webhook/parse-voice";
    const transcriptBox = document.getElementById("transcript");
    let voices = [];

    // Load voices
    function loadVoices() {
      voices = speechSynthesis.getVoices();
    }
    speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices();

    function speakText(text) {
      speechSynthesis.cancel();
      const msg = new SpeechSynthesisUtterance(text);
      msg.lang = "en-US";
      if (voices.length) {
        msg.voice = voices.find(v => v.lang.includes("en-US")) || voices[0];
      }
      speechSynthesis.speak(msg);
    }

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "en-US";
    recognition.interimResults = false;
    recognition.continuous = true;

    let userText = "";

    recognition.onresult = e => {
      const last = e.results.length - 1;
      userText = e.results[last][0].transcript.trim();
      transcriptBox.value += `\nYou: ${userText}`;
      sendToWebhook(userText);
    };

    recognition.onerror = e => {
      console.error("ASR error:", e.error);
      transcriptBox.value += `\nError: ${e.error}`;
      recognition.stop();
      setTimeout(() => recognition.start(), 2000); // Restart on error
    };

    recognition.onend = () => {
      console.warn("ASR stopped. Restarting...");
      setTimeout(() => recognition.start(), 500);
    };

    async function sendToWebhook(text) {
      transcriptBox.value += `\n(Thinking...)`;
      try {
        const res = await fetch(`${WEBHOOK_URL}?text=${encodeURIComponent(text)}`, {
          method: "GET", mode: "cors"
        });
        if (!res.ok) throw new Error(res.statusText);
        const aiReply = await res.text();
        transcriptBox.value += `\nAI: ${aiReply}`;
        speakText(aiReply);
      } catch (err) {
        console.error("Webhook fetch error:", err);
        transcriptBox.value += `\nError: ${err.message}`;
      }
    }

    // Start the conversation
    recognition.start();
  </script>
</body>
</html>
