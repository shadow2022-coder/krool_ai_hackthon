<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Natural AI Conversation</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    body { 
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
      background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 20px;
      animation: gradientShift 8s ease infinite;
      background-size: 400% 400%;
    }
    
    @keyframes gradientShift {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
    
    .container { 
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.2);
      padding: 2.5rem;
      border-radius: 30px;
      text-align: center;
      width: 100%;
      max-width: 420px;
      box-shadow: 
        0 25px 50px rgba(0, 0, 0, 0.1),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    h1 { 
      color: white;
      font-size: 1.8rem;
      font-weight: 300;
      margin-bottom: 2rem;
      text-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      letter-spacing: -0.5px;
    }
    
    .chat-container {
      background: rgba(255, 255, 255, 0.95);
      border-radius: 20px;
      margin-bottom: 2rem;
      max-height: 200px;
      overflow-y: auto;
      box-shadow: inset 0 2px 10px rgba(0, 0, 0, 0.05);
    }
    
    .chat-messages {
      padding: 1rem;
      text-align: left;
      min-height: 120px;
      font-size: 0.95rem;
      line-height: 1.6;
      color: #2d3748;
    }
    
    .message {
      margin-bottom: 1rem;
      animation: fadeIn 0.3s ease;
    }
    
    .user-message {
      color: #667eea;
      font-weight: 500;
    }
    
    .ai-message {
      color: #4a5568;
      padding-left: 1rem;
      border-left: 3px solid #667eea;
      margin-left: 0.5rem;
    }
    
    .status-message {
      color: #718096;
      font-style: italic;
      opacity: 0.8;
    }
    
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    
    .mic-button {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      border: none;
      background: linear-gradient(135deg, #51cf66, #40c057);
      color: white;
      font-size: 1.8rem;
      cursor: pointer;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      box-shadow: 
        0 10px 30px rgba(81, 207, 102, 0.3),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
      position: relative;
      overflow: hidden;
    }
    
    .mic-button:hover {
      transform: scale(1.05);
      box-shadow: 
        0 15px 35px rgba(81, 207, 102, 0.4),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button:active {
      transform: scale(0.95);
    }
    
    .mic-button.listening {
      background: linear-gradient(135deg, #51cf66, #40c057);
      animation: listening-pulse 1.5s infinite;
      box-shadow: 
        0 0 30px rgba(81, 207, 102, 0.5),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button.speaking {
      background: linear-gradient(135deg, #ffd43b, #fab005);
      animation: speaking-wave 0.8s infinite;
      box-shadow: 
        0 0 30px rgba(255, 212, 59, 0.5),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button.inactive {
      background: linear-gradient(135deg, #ff6b6b, #ee5a52);
      box-shadow: 
        0 10px 30px rgba(255, 107, 107, 0.3),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button.processing {
      background: linear-gradient(135deg, #9775fa, #7c3aed);
      animation: processing-spin 1s linear infinite;
      box-shadow: 
        0 0 30px rgba(151, 117, 250, 0.5),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    @keyframes listening-pulse {
      0%, 100% { box-shadow: 0 0 30px rgba(81, 207, 102, 0.5), inset 0 1px 0 rgba(255, 255, 255, 0.2); }
      50% { box-shadow: 0 0 50px rgba(81, 207, 102, 0.8), inset 0 1px 0 rgba(255, 255, 255, 0.2); }
    }
    
    @keyframes speaking-wave {
      0%, 100% { transform: scale(1); }
      25% { transform: scale(1.02); }
      75% { transform: scale(0.98); }
    }
    
    @keyframes processing-spin {
      from { transform: rotate(0deg); }
      to { transform: rotate(360deg); }
    }
    
    .button-label {
      color: white;
      font-size: 0.85rem;
      font-weight: 500;
      margin-top: 1rem;
      opacity: 0.9;
      text-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
    
    .conversation-controls {
      display: flex;
      justify-content: center;
      gap: 1rem;
      margin-top: 1.5rem;
      opacity: 0;
      transition: opacity 0.3s ease;
    }
    
    .conversation-controls.show {
      opacity: 1;
    }
    
    .control-btn {
      width: 50px;
      height: 50px;
      border-radius: 50%;
      border: none;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.2rem;
      transition: all 0.3s ease;
      background: rgba(255, 255, 255, 0.2);
      color: white;
      backdrop-filter: blur(10px);
    }
    
    .control-btn:hover {
      transform: scale(1.1);
      background: rgba(255, 255, 255, 0.3);
    }
    
    @media (max-width: 480px) {
      .container {
        padding: 2rem 1.5rem;
        margin: 10px;
      }
      
      h1 {
        font-size: 1.6rem;
      }
      
      .mic-button {
        width: 70px;
        height: 70px;
        font-size: 1.6rem;
      }
    }
    
    ::-webkit-scrollbar {
      width: 4px;
    }
    
    ::-webkit-scrollbar-track {
      background: rgba(0, 0, 0, 0.05);
      border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb {
      background: rgba(102, 126, 234, 0.3);
      border-radius: 10px;
    }
  </style>
</head>

<body>
  <div class="container">
    <h1>üìû Natural AI Call</h1>
    
    <div class="chat-container">
      <div class="chat-messages" id="chatMessages">
        <div class="status-message">Click the button to start your conversation...</div>
      </div>
    </div>
    
    <button class="mic-button inactive" id="micBtn">üìû</button>
    <div class="button-label" id="buttonLabel">Start Conversation</div>
    
    <div class="conversation-controls" id="conversationControls">
      <button class="control-btn" id="muteBtn" title="Mute/Unmute">üîá</button>
      <button class="control-btn" id="endBtn" title="End Conversation">‚èπÔ∏è</button>
    </div>
  </div>

  <script>
    const WEBHOOK_URL = "https://auto.mithil.hackclub.app/webhook/parse-voice";
    const micBtn = document.getElementById("micBtn");
    const chatMessages = document.getElementById("chatMessages");
    const buttonLabel = document.getElementById("buttonLabel");
    const conversationControls = document.getElementById("conversationControls");
    const muteBtn = document.getElementById("muteBtn");
    const endBtn = document.getElementById("endBtn");
    
    let voices = [];
    let isConversationActive = false;
    let isListening = false;
    let isSpeaking = false;
    let isMuted = false;
    let currentUtterance = null;
    let recognition = null;
    let silenceTimeout = null;

    // Load voices
    function loadVoices() {
      voices = speechSynthesis.getVoices();
    }
    speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices();

    // Initialize speech recognition
    function initializeRecognition() {
      recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = "en-US";
      recognition.interimResults = true;  // Enable interim results for better flow
      recognition.maxAlternatives = 1;
      recognition.continuous = false;  // We'll restart manually for better control
    }

    // Add message to chat
    function addMessage(text, type) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${type}-message`;
      messageDiv.textContent = text;
      chatMessages.appendChild(messageDiv);
      chatMessages.scrollTop = chatMessages.scrollHeight;
    }

    // Stop current speech
    function stopSpeaking() {
      if (isSpeaking && currentUtterance) {
        speechSynthesis.cancel();
        isSpeaking = false;
        micBtn.classList.remove('speaking');
        currentUtterance = null;
      }
    }

    // Start listening for speech
    function startListening() {
      if (!isConversationActive || isListening || isSpeaking) return;
      
      try {
        isListening = true;
        recognition.start();
        micBtn.classList.add('listening');
        micBtn.classList.remove('inactive', 'processing');
        buttonLabel.textContent = "Listening...";
        micBtn.textContent = "üé§";
        
        // Clear initial status message
        if (chatMessages.children.length === 1 && chatMessages.children[0].classList.contains('status-message')) {
          chatMessages.innerHTML = '';
        }
      } catch (err) {
        console.error("Failed to start recognition:", err);
        isListening = false;
      }
    }

    // Stop listening
    function stopListening() {
      if (isListening) {
        try {
          recognition.stop();
        } catch (err) {
          console.error("Error stopping recognition:", err);
        }
        isListening = false;
        micBtn.classList.remove('listening');
      }
    }

    // Speak text with automatic conversation flow
    function speakText(text) {
      stopSpeaking();
      if (isMuted) return;
      
      currentUtterance = new SpeechSynthesisUtterance(text);
      currentUtterance.lang = "en-US";
      
      if (voices.length) {
        currentUtterance.voice = voices.find(v => v.lang.includes("en-US")) || voices[0];
      }
      
      currentUtterance.onstart = () => {
        isSpeaking = true;
        micBtn.classList.add('speaking');
        micBtn.classList.remove('listening', 'processing', 'inactive');
        buttonLabel.textContent = "AI Speaking...";
        micBtn.textContent = "üó£Ô∏è";
      };
      
      currentUtterance.onend = () => {
        isSpeaking = false;
        micBtn.classList.remove('speaking');
        currentUtterance = null;
        
        // Automatically start listening again after AI finishes speaking
        if (isConversationActive) {
          setTimeout(() => {
            startListening();
          }, 500); // Brief pause before listening again
        }
      };
      
      currentUtterance.onerror = () => {
        isSpeaking = false;
        micBtn.classList.remove('speaking');
        currentUtterance = null;
        if (isConversationActive) {
          setTimeout(() => startListening(), 500);
        }
      };
      
      speechSynthesis.speak(currentUtterance);
    }

    // Start conversation
    function startConversation() {
      if (!recognition) initializeRecognition();
      
      isConversationActive = true;
      conversationControls.classList.add('show');
      micBtn.classList.remove('inactive');
      buttonLabel.textContent = "Starting...";
      
      // Start listening immediately
      setTimeout(() => {
        startListening();
      }, 300);
    }

    // End conversation
    function endConversation() {
      isConversationActive = false;
      stopListening();
      stopSpeaking();
      
      conversationControls.classList.remove('show');
      micBtn.classList.remove('listening', 'speaking', 'processing');
      micBtn.classList.add('inactive');
      micBtn.textContent = "üìû";
      buttonLabel.textContent = "Start Conversation";
      
      addMessage("Conversation ended", 'status');
    }

    // Send to webhook
    async function sendToWebhook(text) {
      micBtn.classList.add('processing');
      micBtn.classList.remove('listening');
      buttonLabel.textContent = "Thinking...";
      micBtn.textContent = "ü§î";
      
      try {
        const res = await fetch(`${WEBHOOK_URL}?text=${encodeURIComponent(text)}`, {
          method: "GET", 
          mode: "cors"
        });
        
        if (!res.ok) throw new Error(res.statusText);
        
        const aiReply = await res.text();
        addMessage(`AI: ${aiReply}`, 'ai');
        micBtn.classList.remove('processing');
        speakText(aiReply);
        
      } catch (err) {
        console.error("Fetch error:", err);
        addMessage(`Error: ${err.message}`, 'status');
        micBtn.classList.remove('processing');
        if (isConversationActive) {
          setTimeout(() => startListening(), 1000);
        }
      }
    }

    // Main button click handler
    micBtn.addEventListener("click", () => {
      if (!isConversationActive) {
        startConversation();
      }
    });

    // Mute button
    muteBtn.addEventListener("click", () => {
      isMuted = !isMuted;
      muteBtn.textContent = isMuted ? "üîá" : "üîä";
      muteBtn.title = isMuted ? "Unmute" : "Mute";
      if (isMuted) stopSpeaking();
    });

    // End button
    endBtn.addEventListener("click", endConversation);

    // Initialize recognition when page loads
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      initializeRecognition();
      
      // Set up recognition event handlers
      recognition.onresult = (e) => {
        let finalTranscript = '';
        let interimTranscript = '';
        
        for (let i = e.resultIndex; i < e.results.length; i++) {
          const transcript = e.results[i][0].transcript;
          if (e.results[i].isFinal) {
            finalTranscript += transcript;
          } else {
            interimTranscript += transcript;
          }
        }
        
        if (finalTranscript.trim()) {
          addMessage(`You: ${finalTranscript.trim()}`, 'user');
          sendToWebhook(finalTranscript.trim());
        }
      };

      recognition.onend = () => {
        isListening = false;
        micBtn.classList.remove('listening');
        
        // If conversation is still active but we're not speaking, restart listening
        if (isConversationActive && !isSpeaking) {
          setTimeout(() => {
            startListening();
          }, 100);
        }
      };

      recognition.onerror = (e) => {
        console.error("Speech recognition error:", e.error);
        isListening = false;
        micBtn.classList.remove('listening');
        
        if (e.error !== 'aborted' && e.error !== 'no-speech') {
          addMessage(`Recognition error: ${e.error}`, 'status');
        }
        
        // Restart listening if conversation is still active
        if (isConversationActive && !isSpeaking && e.error !== 'aborted') {
          setTimeout(() => {
            startListening();
          }, 1000);
        }
      };
    } else {
      buttonLabel.textContent = "Speech recognition not supported";
      micBtn.disabled = true;
    }

    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if (e.code === 'Space' && !isConversationActive && !e.repeat) {
        e.preventDefault();
        startConversation();
      } else if (e.code === 'Escape' && isConversationActive) {
        e.preventDefault();
        endConversation();
      }
    });
  </script>
</body>
</html>
