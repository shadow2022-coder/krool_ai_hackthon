<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Interactive ASR + TTS Voice AI</title>
  <style>
    body { font-family: sans-serif; display: flex; align-items: center; justify-content: center; height: 100vh; margin: 0; background: #2a284a; color: #e2e8f0; }
    .container { background: #363456; padding: 2rem; border-radius: 12px; width: 90%; max-width: 400px; text-align: center; }
    button { padding: 1rem 2rem; font-size: 1rem; background: #6d28d9; color: white; border: none; border-radius: 8px; cursor: pointer; }
    button:disabled { opacity: 0.5; cursor: default; }
    textarea { width: 100%; height: 150px; margin-top: 1rem; padding: .5rem; border-radius: 6px; border: 1px solid #4a486b; background: #363456; color: #e2e8f0; font-size: 1rem; }
  </style>
</head>
<body>
  <div class="container">
    <h2>üéôÔ∏è Voice AI (Press to Talk)</h2>
    <button id="toggleBtn">Start Listening</button>
    <textarea id="transcript" readonly placeholder="Transcript will appear here‚Ä¶"></textarea>
  </div>

  <script>
    const WEBHOOK_URL = "https://auto.mithil.hackclub.app/webhook/parse-voice";
    const btn = document.getElementById('toggleBtn');
    const transcriptBox = document.getElementById('transcript');

    let listening = false;
    let voices = [];

    function loadVoices() {
      voices = speechSynthesis.getVoices();
    }
    speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices();

    function speakText(text) {
      speechSynthesis.cancel();  // Stop any ongoing speech immediately :contentReference[oaicite:1]{index=1}
      const msg = new SpeechSynthesisUtterance(text);
      msg.lang = 'en-US';
      if (voices.length) msg.voice = voices.find(v => v.lang.includes('en-US')) || voices[0];
      msg.onstart = () => recognition.stop();  // Stop ASR while AI speaks
      msg.onend = () => { if (listening) recognition.start(); };
      msg.onerror = () => console.error('TTS error');
      speechSynthesis.speak(msg);
    }

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'en-US';
    recognition.interimResults = false;
    recognition.continuous = false;  // single-shot recognition :contentReference[oaicite:2]{index=2}

    recognition.onresult = async e => {
      const text = e.results[0][0].transcript.trim();
      transcriptBox.value += `\nYou: ${text}`;
      await handleUser(text);
    };
    recognition.onspeechend = () => recognition.stop();
    recognition.onend = () => {
      if (listening) btn.click();  // auto-stop listening if ended
    };
    recognition.onerror = e => {
      transcriptBox.value += `\nASR error: ${e.error}`;
      recognition.stop();
    };

    async function handleUser(text) {
      recognition.stop();
      transcriptBox.value += `\n(Thinking‚Ä¶)`;
      try {
        const res = await fetch(`${WEBHOOK_URL}?text=${encodeURIComponent(text)}`);
        const ai = await res.text();
        transcriptBox.value += `\nAI: ${ai}`;
        speakText(ai);
      } catch (err) {
        transcriptBox.value += `\nError: ${err.message}`;
      }
    }

    btn.onclick = () => {
      listening = !listening;
      btn.textContent = listening ? 'Stop Listening' : 'Start Listening';
      if (listening) {
        recognition.start();
      } else {
        recognition.stop();
        speechSynthesis.cancel();
      }
    };
  </script>
</body>
</html>
