<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>STT + Automatic TTS Web App</title>
  <style>
    body { font-family: sans-serif; display: flex; align-items: center; justify-content: center; height: 100vh; margin: 0; background: #f4f4f4; }
    .container { background: white; padding: 2rem; border-radius: 12px; box-shadow: 0 8px 16px rgba(0,0,0,0.1); text-align: center; width: 90%; max-width: 400px; }
    button { padding: 1rem 2rem; font-size: 1rem; background-color: #2563eb; color: white; border: none; border-radius: 8px; cursor: pointer; }
    button:disabled { opacity: 0.6; cursor: default; }
    textarea { width: 100%; height: 120px; margin-top: 1rem; padding: 0.5rem; border-radius: 6px; border: 1px solid #ccc; font-size: 1rem; }
  </style>
</head>
<body>
  <div class="container">
    <h2>Press & Speak â€” auto TTS reply</h2>
    <textarea id="transcript" readonly placeholder="Your speech & AI reply appear hereâ€¦"></textarea><br>
    <button id="speakBtn">Hold to Speak</button>
  </div>

  <script>
    const WEBHOOK_URL = "https://auto.mithil.hackclub.app/webhook/parse-voice";
    const speakBtn = document.getElementById("speakBtn");
    const transcriptBox = document.getElementById("transcript");
    let voices = [];

    // Load voices when available
    function loadVoices() {
      voices = speechSynthesis.getVoices();
      console.log("Voices loaded:", voices);
    }
    speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices();

    function speakText(text) {
      speechSynthesis.cancel();
      const msg = new SpeechSynthesisUtterance(text);
      msg.lang = "en-US";
      if (voices.length) {
        msg.voice = voices.find(v => v.lang.includes("en-US")) || voices[0];
      }
      msg.onerror = e => console.error("TTS error:", e.error);
      msg.onstart = () => console.log("TTS started");
      msg.onend = () => console.log("TTS ended");
      speechSynthesis.speak(msg);
    }

    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "en-US";
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;

    let isListening = false;
    let userText = "";

    // Start recording
    speakBtn.addEventListener("mousedown", () => {
      if (!isListening) {
        isListening = true;
        transcriptBox.value = "";
        recognition.start();
        speakBtn.innerText = "Listeningâ€¦";
      }
    });

    // Stop recording and send
    speakBtn.addEventListener("mouseup", () => {
      if (isListening) {
        recognition.stop();
        isListening = false;
        speakBtn.innerText = "Hold to Speak";
      }
    });

    recognition.onresult = e => {
      userText = e.results[0][0].transcript;
      transcriptBox.value = "You: " + userText;
      sendToWebhook(userText);
    };

    recognition.onerror = e => {
      console.error("STT error:", e.error);
      transcriptBox.value = "Error: " + e.error;
      isListening = false;
      speakBtn.innerText = "Hold to Speak";
    };

    async function sendToWebhook(text) {
      transcriptBox.value += "\n(Waiting for AI reply...)";
      try {
        const res = await fetch(`${WEBHOOK_URL}?text=${encodeURIComponent(text)}`, {
          method: "GET", mode: "cors"
        });
        if (!res.ok) throw new Error(res.statusText);
        const aiReply = await res.text();
        transcriptBox.value = "You: " + userText + "\nAI: " + aiReply;
        speakText(aiReply);  // ðŸ”Š Play TTS automatically
      } catch (err) {
        console.error("Fetch error:", err);
        transcriptBox.value += "\nError: " + err.message;
      }
    }
  </script>
</body>
</html>
