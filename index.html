<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Interruptible AI Conversation</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    body { 
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
      background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 20px;
      animation: gradientShift 8s ease infinite;
      background-size: 400% 400%;
    }
    
    @keyframes gradientShift {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
    
    .container { 
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(20px);
      border: 1px solid rgba(255, 255, 255, 0.2);
      padding: 2.5rem;
      border-radius: 30px;
      text-align: center;
      width: 100%;
      max-width: 420px;
      box-shadow: 
        0 25px 50px rgba(0, 0, 0, 0.1),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    h1 { 
      color: white;
      font-size: 1.8rem;
      font-weight: 300;
      margin-bottom: 2rem;
      text-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      letter-spacing: -0.5px;
    }
    
    .chat-container {
      background: rgba(255, 255, 255, 0.95);
      border-radius: 20px;
      margin-bottom: 2rem;
      max-height: 200px;
      overflow-y: auto;
      box-shadow: inset 0 2px 10px rgba(0, 0, 0, 0.05);
    }
    
    .chat-messages {
      padding: 1rem;
      text-align: left;
      min-height: 120px;
      font-size: 0.95rem;
      line-height: 1.6;
      color: #2d3748;
    }
    
    .message {
      margin-bottom: 1rem;
      animation: fadeIn 0.3s ease;
    }
    
    .user-message {
      color: #667eea;
      font-weight: 500;
    }
    
    .ai-message {
      color: #4a5568;
      padding-left: 1rem;
      border-left: 3px solid #667eea;
      margin-left: 0.5rem;
    }
    
    .interrupted-message {
      color: #e53e3e;
      font-style: italic;
      opacity: 0.8;
    }
    
    .status-message {
      color: #718096;
      font-style: italic;
      opacity: 0.8;
    }
    
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    
    .mic-button {
      width: 80px;
      height: 80px;
      border-radius: 50%;
      border: none;
      background: linear-gradient(135deg, #51cf66, #40c057);
      color: white;
      font-size: 1.8rem;
      cursor: pointer;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      box-shadow: 
        0 10px 30px rgba(81, 207, 102, 0.3),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
      position: relative;
      overflow: hidden;
    }
    
    .mic-button:hover {
      transform: scale(1.05);
      box-shadow: 
        0 15px 35px rgba(81, 207, 102, 0.4),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button:active {
      transform: scale(0.95);
    }
    
    .mic-button.listening {
      background: linear-gradient(135deg, #51cf66, #40c057);
      animation: listening-pulse 1.5s infinite;
      box-shadow: 
        0 0 30px rgba(81, 207, 102, 0.5),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button.speaking {
      background: linear-gradient(135deg, #ffd43b, #fab005);
      animation: speaking-wave 0.8s infinite;
      box-shadow: 
        0 0 30px rgba(255, 212, 59, 0.5),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button.interrupted {
      background: linear-gradient(135deg, #ff8787, #ff6b6b);
      animation: interrupted-flash 0.3s ease-out;
      box-shadow: 
        0 0 30px rgba(255, 135, 135, 0.6),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button.inactive {
      background: linear-gradient(135deg, #ff6b6b, #ee5a52);
      box-shadow: 
        0 10px 30px rgba(255, 107, 107, 0.3),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    .mic-button.processing {
      background: linear-gradient(135deg, #9775fa, #7c3aed);
      animation: processing-spin 1s linear infinite;
      box-shadow: 
        0 0 30px rgba(151, 117, 250, 0.5),
        inset 0 1px 0 rgba(255, 255, 255, 0.2);
    }
    
    @keyframes listening-pulse {
      0%, 100% { box-shadow: 0 0 30px rgba(81, 207, 102, 0.5), inset 0 1px 0 rgba(255, 255, 255, 0.2); }
      50% { box-shadow: 0 0 50px rgba(81, 207, 102, 0.8), inset 0 1px 0 rgba(255, 255, 255, 0.2); }
    }
    
    @keyframes speaking-wave {
      0%, 100% { transform: scale(1); }
      25% { transform: scale(1.02); }
      75% { transform: scale(0.98); }
    }
    
    @keyframes interrupted-flash {
      0% { transform: scale(1); }
      50% { transform: scale(1.1); }
      100% { transform: scale(1); }
    }
    
    @keyframes processing-spin {
      from { transform: rotate(0deg); }
      to { transform: rotate(360deg); }
    }
    
    .button-label {
      color: white;
      font-size: 0.85rem;
      font-weight: 500;
      margin-top: 1rem;
      opacity: 0.9;
      text-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }
    
    .conversation-controls {
      display: flex;
      justify-content: center;
      gap: 1rem;
      margin-top: 1.5rem;
      opacity: 0;
      transition: opacity 0.3s ease;
    }
    
    .conversation-controls.show {
      opacity: 1;
    }
    
    .control-btn {
      width: 50px;
      height: 50px;
      border-radius: 50%;
      border: none;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.2rem;
      transition: all 0.3s ease;
      background: rgba(255, 255, 255, 0.2);
      color: white;
      backdrop-filter: blur(10px);
    }
    
    .control-btn:hover {
      transform: scale(1.1);
      background: rgba(255, 255, 255, 0.3);
    }
    
    .sensitivity-indicator {
      position: absolute;
      top: -5px;
      right: -5px;
      width: 20px;
      height: 20px;
      background: rgba(81, 207, 102, 0.8);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.7rem;
      opacity: 0;
      transition: opacity 0.3s ease;
    }
    
    .sensitivity-indicator.active {
      opacity: 1;
      animation: sensitivity-pulse 0.5s ease-out;
    }
    
    @keyframes sensitivity-pulse {
      0% { transform: scale(0.5); }
      100% { transform: scale(1); }
    }
    
    @media (max-width: 480px) {
      .container {
        padding: 2rem 1.5rem;
        margin: 10px;
      }
      
      h1 {
        font-size: 1.6rem;
      }
      
      .mic-button {
        width: 70px;
        height: 70px;
        font-size: 1.6rem;
      }
    }
    
    ::-webkit-scrollbar {
      width: 4px;
    }
    
    ::-webkit-scrollbar-track {
      background: rgba(0, 0, 0, 0.05);
      border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb {
      background: rgba(102, 126, 234, 0.3);
      border-radius: 10px;
    }
  </style>
</head>

<body>
  <div class="container">
    <h1>üîä Smart AI Conversation</h1>
    
    <div class="chat-container">
      <div class="chat-messages" id="chatMessages">
        <div class="status-message">Click to start an intelligent conversation that adapts to you...</div>
      </div>
    </div>
    
    <button class="mic-button inactive" id="micBtn">
      üìû
      <div class="sensitivity-indicator" id="sensitivityIndicator">üëÇ</div>
    </button>
    <div class="button-label" id="buttonLabel">Start Smart Conversation</div>
    
    <div class="conversation-controls" id="conversationControls">
      <button class="control-btn" id="sensitivityBtn" title="Voice Sensitivity">üéöÔ∏è</button>
      <button class="control-btn" id="muteBtn" title="Mute/Unmute">üîá</button>
      <button class="control-btn" id="endBtn" title="End Conversation">‚èπÔ∏è</button>
    </div>
  </div>

  <script>
    const WEBHOOK_URL = "https://auto.mithil.hackclub.app/webhook/parse-voice";
    const micBtn = document.getElementById("micBtn");
    const chatMessages = document.getElementById("chatMessages");
    const buttonLabel = document.getElementById("buttonLabel");
    const conversationControls = document.getElementById("conversationControls");
    const muteBtn = document.getElementById("muteBtn");
    const endBtn = document.getElementById("endBtn");
    const sensitivityBtn = document.getElementById("sensitivityBtn");
    const sensitivityIndicator = document.getElementById("sensitivityIndicator");
    
    let voices = [];
    let isConversationActive = false;
    let isListening = false;
    let isSpeaking = false;
    let isMuted = false;
    let currentUtterance = null;
    let backgroundRecognition = null;
    let mainRecognition = null;
    let lastSpeechTime = 0;
    let interruptionSensitivity = 3; // 1-5 scale, 3 is medium
    let voiceActivityThreshold = 0.3;
    let isProcessingInterruption = false;

    // Load voices
    function loadVoices() {
      voices = speechSynthesis.getVoices();
    }
    speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices();

    // Initialize speech recognition instances
    function initializeRecognition() {
      // Main recognition for regular conversation
      mainRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      mainRecognition.lang = "en-US";
      mainRecognition.interimResults = true;
      mainRecognition.maxAlternatives = 1;
      mainRecognition.continuous = false;

      // Background recognition for interruption detection
      backgroundRecognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      backgroundRecognition.lang = "en-US";
      backgroundRecognition.interimResults = true;
      backgroundRecognition.maxAlternatives = 1;
      backgroundRecognition.continuous = true; // Continuous listening for interruptions
    }

    // Add message to chat
    function addMessage(text, type) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${type}-message`;
      messageDiv.textContent = text;
      chatMessages.appendChild(messageDiv);
      chatMessages.scrollTop = chatMessages.scrollHeight;
    }

    // Stop current speech immediately
    function stopSpeaking(wasInterrupted = false) {
      if (isSpeaking && currentUtterance) {
        speechSynthesis.cancel();
        isSpeaking = false;
        micBtn.classList.remove('speaking');
        
        if (wasInterrupted) {
          micBtn.classList.add('interrupted');
          addMessage("AI interrupted - listening to you...", 'interrupted');
          setTimeout(() => {
            micBtn.classList.remove('interrupted');
          }, 500);
        }
        
        currentUtterance = null;
      }
    }

    // Handle voice activity detection for interruption
    function handleVoiceActivity() {
      if (isSpeaking && !isProcessingInterruption) {
        const currentTime = Date.now();
        const timeSinceLastSpeech = currentTime - lastSpeechTime;
        
        // More sensitive interruption based on sensitivity setting
        const sensitivityDelay = Math.max(100, 600 - (interruptionSensitivity * 100));
        
        if (timeSinceLastSpeech > sensitivityDelay) {
          isProcessingInterruption = true;
          stopSpeaking(true);
          
          // Show sensitivity indicator
          sensitivityIndicator.classList.add('active');
          setTimeout(() => {
            sensitivityIndicator.classList.remove('active');
          }, 800);
          
          // Switch to main recognition for processing the interruption
          setTimeout(() => {
            startMainListening();
            isProcessingInterruption = false;
          }, 200);
        }
      }
      lastSpeechTime = Date.now();
    }

    // Start background listening for interruptions
    function startBackgroundListening() {
      if (!isConversationActive || !backgroundRecognition) return;
      
      try {
        backgroundRecognition.start();
      } catch (err) {
        console.log("Background recognition already running or failed:", err);
      }
    }

    // Start main listening
    function startMainListening() {
      if (!isConversationActive || isListening || isSpeaking) return;
      
      try {
        isListening = true;
        mainRecognition.start();
        micBtn.classList.add('listening');
        micBtn.classList.remove('inactive', 'processing', 'interrupted');
        buttonLabel.textContent = "Listening...";
        micBtn.textContent = "üé§";
        
        // Clear initial status message
        if (chatMessages.children.length === 1 && chatMessages.children[0].classList.contains('status-message')) {
          chatMessages.innerHTML = '';
        }
      } catch (err) {
        console.error("Failed to start main recognition:", err);
        isListening = false;
      }
    }

    // Stop main listening
    function stopMainListening() {
      if (isListening && mainRecognition) {
        try {
          mainRecognition.stop();
        } catch (err) {
          console.error("Error stopping main recognition:", err);
        }
        isListening = false;
        micBtn.classList.remove('listening');
      }
    }

    // Speak text with interruption capability
    function speakText(text) {
      stopSpeaking();
      if (isMuted) return;
      
      currentUtterance = new SpeechSynthesisUtterance(text);
      currentUtterance.lang = "en-US";
      currentUtterance.rate = 0.9; // Slightly slower for better interruption detection
      
      if (voices.length) {
        currentUtterance.voice = voices.find(v => v.lang.includes("en-US")) || voices[0];
      }
      
      currentUtterance.onstart = () => {
        isSpeaking = true;
        micBtn.classList.add('speaking');
        micBtn.classList.remove('listening', 'processing', 'inactive', 'interrupted');
        buttonLabel.textContent = "AI Speaking (interrupt anytime)...";
        micBtn.textContent = "üó£Ô∏è";
        
        // Start background listening for interruptions while speaking
        if (isConversationActive) {
          startBackgroundListening();
        }
      };
      
      currentUtterance.onend = () => {
        isSpeaking = false;
        micBtn.classList.remove('speaking');
        currentUtterance = null;
        
        // Stop background listening and start main listening
        if (isConversationActive) {
          setTimeout(() => {
            startMainListening();
          }, 300);
        }
      };
      
      currentUtterance.onerror = () => {
        isSpeaking = false;
        micBtn.classList.remove('speaking');
        currentUtterance = null;
        if (isConversationActive) {
          setTimeout(() => startMainListening(), 300);
        }
      };
      
      speechSynthesis.speak(currentUtterance);
    }

    // Start conversation
    function startConversation() {
      if (!mainRecognition || !backgroundRecognition) initializeRecognition();
      
      isConversationActive = true;
      conversationControls.classList.add('show');
      micBtn.classList.remove('inactive');
      buttonLabel.textContent = "Starting intelligent conversation...";
      
      // Start main listening immediately
      setTimeout(() => {
        startMainListening();
      }, 500);
    }

    // End conversation
    function endConversation() {
      isConversationActive = false;
      isProcessingInterruption = false;
      stopMainListening();
      stopSpeaking();
      
      // Stop background recognition
      if (backgroundRecognition) {
        try {
          backgroundRecognition.stop();
        } catch (err) {
          console.log("Background recognition already stopped");
        }
      }
      
      conversationControls.classList.remove('show');
      micBtn.classList.remove('listening', 'speaking', 'processing', 'interrupted');
      micBtn.classList.add('inactive');
      micBtn.textContent = "üìû";
      buttonLabel.textContent = "Start Smart Conversation";
      
      addMessage("Conversation ended", 'status');
    }

    // Send to webhook
    async function sendToWebhook(text) {
      micBtn.classList.add('processing');
      micBtn.classList.remove('listening', 'interrupted');
      buttonLabel.textContent = "Processing your input...";
      micBtn.textContent = "ü§î";
      
      try {
        const res = await fetch(`${WEBHOOK_URL}?text=${encodeURIComponent(text)}`, {
          method: "GET", 
          mode: "cors"
        });
        
        if (!res.ok) throw new Error(res.statusText);
        
        const aiReply = await res.text();
        addMessage(`AI: ${aiReply}`, 'ai');
        micBtn.classList.remove('processing');
        speakText(aiReply);
        
      } catch (err) {
        console.error("Fetch error:", err);
        addMessage(`Error: ${err.message}`, 'status');
        micBtn.classList.remove('processing');
        if (isConversationActive) {
          setTimeout(() => startMainListening(), 1000);
        }
      }
    }

    // Main button click handler
    micBtn.addEventListener("click", () => {
      if (!isConversationActive) {
        startConversation();
      }
    });

    // Sensitivity button
    sensitivityBtn.addEventListener("click", () => {
      interruptionSensitivity = (interruptionSensitivity % 5) + 1;
      sensitivityBtn.textContent = `${interruptionSensitivity}üìä`;
      
      const labels = ["Very Low", "Low", "Medium", "High", "Very High"];
      addMessage(`Interruption sensitivity: ${labels[interruptionSensitivity - 1]}`, 'status');
    });

    // Mute button
    muteBtn.addEventListener("click", () => {
      isMuted = !isMuted;
      muteBtn.textContent = isMuted ? "üîá" : "üîä";
      muteBtn.title = isMuted ? "Unmute" : "Mute";
      if (isMuted) stopSpeaking();
    });

    // End button
    endBtn.addEventListener("click", endConversation);

    // Initialize recognition when page loads
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      initializeRecognition();
      
      // Main recognition event handlers
      mainRecognition.onresult = (e) => {
        let finalTranscript = '';
        
        for (let i = e.resultIndex; i < e.results.length; i++) {
          const transcript = e.results[i][0].transcript;
          if (e.results[i].isFinal) {
            finalTranscript += transcript;
          }
        }
        
        if (finalTranscript.trim()) {
          addMessage(`You: ${finalTranscript.trim()}`, 'user');
          sendToWebhook(finalTranscript.trim());
        }
      };

      mainRecognition.onend = () => {
        isListening = false;
        micBtn.classList.remove('listening');
        
        // Restart if conversation is active and we're not processing an interruption
        if (isConversationActive && !isSpeaking && !isProcessingInterruption) {
          setTimeout(() => {
            startMainListening();
          }, 100);
        }
      };

      mainRecognition.onerror = (e) => {
        console.error("Main recognition error:", e.error);
        isListening = false;
        micBtn.classList.remove('listening');
        
        if (e.error !== 'aborted' && e.error !== 'no-speech') {
          console.log(`Recognition error: ${e.error}`);
        }
        
        if (isConversationActive && !isSpeaking && e.error !== 'aborted') {
          setTimeout(() => {
            startMainListening();
          }, 1000);
        }
      };

      // Background recognition for interruption detection
      backgroundRecognition.onresult = (e) => {
        // Just detect voice activity, don't process the speech
        if (e.results.length > 0) {
          handleVoiceActivity();
        }
      };

      backgroundRecognition.onend = () => {
        // Restart background listening if conversation is active and AI is speaking
        if (isConversationActive && isSpeaking) {
          setTimeout(() => {
            startBackgroundListening();
          }, 100);
        }
      };

      backgroundRecognition.onerror = (e) => {
        if (e.error !== 'aborted' && e.error !== 'no-speech') {
          console.log("Background recognition error:", e.error);
        }
        
        // Restart background listening if needed
        if (isConversationActive && isSpeaking && e.error !== 'aborted') {
          setTimeout(() => {
            startBackgroundListening();
          }, 500);
        }
      };
    } else {
      buttonLabel.textContent = "Speech recognition not supported";
      micBtn.disabled = true;
    }

    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if (e.code === 'Space' && !isConversationActive && !e.repeat) {
        e.preventDefault();
        startConversation();
      } else if (e.code === 'Escape' && isConversationActive) {
        e.preventDefault();
        endConversation();
      } else if (e.code === 'KeyS' && isConversationActive && !e.repeat) {
        e.preventDefault();
        sensitivityBtn.click();
      }
    });

    // Initialize sensitivity button display
    sensitivityBtn.textContent = `${interruptionSensitivity}üìä`;
  </script>
</body>
</html>
